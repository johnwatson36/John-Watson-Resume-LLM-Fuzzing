api_name,parameters,parameter_descriptions,example_usage,temperature,score
torch.fft.irfft,"['input', 'signal_ndim', 'normalized', 'onesided', 'signal_sizes']","['Complex input tensor, the last dimension of which will be transformed.', 'The number of dimensions in each item of the input signal.', 'If True, normalizes the results so that the energy of the input signal is preserved.', 'If True, assumes input contains only the positive frequency terms.', 'Signal sizes defining the IFFT number of points.']","torch.fft.irfft(input, signal_ndim, normalized, onesided, signal_sizes)",1.0,7
torch.nn.functional.pad,"['input', 'pad', 'mode', 'value']","['Input tensor of rank at least 2.', 'Padding size. Should be a sequence of length 4 in case of 2D Input.', ""Type of padding. Can be 'constant', 'reflect', 'replicate' or 'circular'."", ""Fill value for 'constant' padding mode.""]","torch.nn.functional.pad(input, pad, mode, value)",1.0,6
torch.symeig,"['input', 'eigenvectors', 'upper']","['The input tensor of size (*, n, n) where * is zero or more batch dimensions consisting of symmetric matrices.', 'If True, computes eigenvectors in addition to eigenvalues.', 'If True, consider only upper triangular part.']","torch.symeig(input, eigenvectors, upper)",1.0,5
torch.unique,"['input', 'sorted', 'return_inverse', 'return_counts', 'dim']","['The input tensor.', 'If True, the unique elements will be sorted.', 'If True, also returns the indices for where elements in the original input ended up in the returned unique list.', 'If True, also returns the counts for each element.', 'If not None, unique elements along this dimension.']","torch.unique(input, sorted, return_inverse, return_counts, dim)",1.0,7
torch.Tensor.scatter_,"['dim', 'index', 'src']","['The axis along which to index.', 'The indices of elements to scatter.', 'The source element(s) to scatter.']","Tensor.scatter_(dim, index, src)",1.0,5
torch.distributions.Normal,"['loc', 'scale']","['The mean(s) of the distribution(s).', 'The standard deviation(s) of the distribution(s).']","torch.distributions.Normal(loc, scale)",1.0,4
torch.nn.ReflectionPad2d,['padding'],"['The size of the padding. If is int, uses the same padding in all directions.']",torch.nn.ReflectionPad2d(padding),1.0,3
torch.nn.ConvTranspose1d,"['in_channels', 'out_channels', 'kernel_size', 'stride', 'padding', 'output_padding', 'groups', 'bias', 'dilation']","['Number of channels in the input image.', 'Number of channels produced by the convolution.', 'Size of the convolving kernel / filter.', 'Stride of the convolution.', 'Zero-padding added to both sides of the input.', 'Additional size added to one side of each dimension in the output shape.', 'Number of blocked connections from input channels to output channels.', 'If set to False, the layer will not learn an additive bias.', 'Spacing between kernel elements.']","torch.nn.ConvTranspose1d(in_channels, out_channels, kernel_size, stride, padding, output_padding, groups, bias, dilation)",1.0,11
torch.nn.BCELoss,"['input', 'target', 'weight', 'size_average', 'reduce', 'reduction']","['The predicted probabilities.', 'The targets.', 'A manual rescaling weight given to each class.', 'If set to False, the losses are averaged over each loss element in the batch.', ""Deprecated (use 'reduction' instead). If set to False, the losses are instead summed."", ""Specifies the reduction to apply to the output. Options are 'none', 'mean', or 'sum'.""]","torch.nn.BCELoss(input, target, weight, size_average, reduce, reduction)",1.0,8
torch.utils.data.DataLoader,"['dataset', 'batch_size', 'shuffle', 'sampler', 'batch_sampler', 'num_workers', 'collate_fn', 'pin_memory', 'drop_last', 'timeout', 'worker_init_fn']","['Dataset from which to load the data.', 'How many samples per batch to load.', 'Set to True to have the data reshuffled at every epoch.', 'Defines the strategy to draw samples from the dataset.', 'Like sampler, but returns a batch of indices at a time.', 'How many subprocesses to use for data loading.', 'Merges a list of samples to form a batch of Tensor(s).', 'If True, the data loader will copy tensors into CUDA pinned memory before returning them.', 'If True, drops the last incomplete batch if the dataset size is not divisible by the batch size.', 'If positive, provides timeout option for the collecting process.', 'If not None, will be called on each worker subprocess with the worker id as an input.']","torch.utils.data.DataLoader(dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn)",1.0,13
