api_name,parameters,parameter_descriptions,example_usage,temperature
torch.nn.functional.grid_sample,"['input', 'grid', 'mode', 'padding_mode', 'align_corners']","['Input tensor of shape (N, C, Hin, Win)', 'Input grid of shape (N, Hout, Wout, 2)', ""Interpolation mode to calculate output values. Options are 'bilinear', 'nearest' and 'bicubic'"", ""Padding mode for outside grid values. Options are 'zeros', 'border', 'reflection'"", 'If True, the grid centers align with the pixel centers; if False, the grid centers align with the pixel corners']","torch.nn.functional.grid_sample(input, grid, mode='bilinear', padding_mode='zeros', align_corners=None)",
torch.nn.utils.clip_grad_norm_,"['parameters', 'max_norm', 'norm_type']","['Iterable containing the parameters to clip', 'Max norm of the gradients', ""Type of the used p-norm. Can be 'inf' for infinity norm""]","torch.nn.utils.clip_grad_norm_(parameters, max_norm, norm_type=2)",
torch.nn.functional.unfold,"['input', 'kernel_size', 'dilation', 'padding', 'stride']","['Input tensor of shape (minibatch, in_channels, iH, iW)', 'The size of the sliding blocks', 'The stride of the sliding blocks', 'Implicit zero paddings on both sides of the input', 'The stride of the sliding block']","torch.nn.functional.unfold(input, kernel_size, dilation=1, padding=0, stride=1)",
torch.nn.functional.pdist,"['input', 'p']","['Input tensor of shape (N, M)', 'The p-norm degree. Default: 2']","torch.nn.functional.pdist(input, p=2)",
torch.nn.functional.gumbel_softmax,"['logits', 'tau', 'hard', 'dim', 'eps']","['Input', 'The temperature parameter', 'If True, the returned samples will be one-hot encoded, otherwise they will be probabilities from the Gumbel-Softmax distribution', 'A dimension along which softmax will be computed', 'Small value where we will use to prevent division by zero']","torch.nn.functional.gumbel_softmax(logits, tau=1, hard=False, dim=-1, eps=1e-10)",
torch.nn.functional.pad,"['input', 'pad', 'mode', 'value']","['Input tensor of arbitrary shape', 'List of padding values', ""Type of padding. Can be 'constant', 'reflect', 'replicate' or 'circular'"", ""Fill value for 'constant' padding""]","torch.nn.functional.pad(input, pad, mode='constant', value=0)",
torch.nn.functional.normalize,"['input', 'p', 'dim', 'eps']","['Input tensor of any shape', 'The p value in the p-norm to compute for the `dim` dimension', 'The dimension to reduce', 'Small value to avoid division by zero']","torch.nn.functional.normalize(input, p=2, dim=1, eps=1e-12)",
torch.nn.functional.interpolate,"['input', 'size', 'scale_factor', 'mode', 'align_corners']","['Input tensor', 'Output spatial size', 'Multiplier for spatial size', ""Algorithm used for upsampling: 'nearest', 'linear', 'bilinear', 'bicubic', 'trilinear', 'area'"", 'Geometrically, we consider the pixels of the input and output as squares rather than points']","torch.nn.functional.interpolate(input, size=None, scale_factor=2, mode='nearest', align_corners=None)",
torch.nn.functional.softplus,"['input', 'beta', 'threshold']","['Input tensor', 'The beta value for the Softplus function', 'Values above this revert to a linear function']","torch.nn.functional.softplus(input, beta=1, threshold=20)",
torch.nn.functional.softshrink,"['input', 'lambd']","['Input tensor', 'The lambda value for the Softshrink function']","torch.nn.functional.softshrink(input, lambd=0.5)",
